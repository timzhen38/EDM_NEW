{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "00000-472cbcdb-4e9b-46f5-bc9e-f4b4e97c8bd3",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5610,
    "execution_start": 1634168360884,
    "source_hash": "99e17f2b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/37159070/multiple-linear-regression-model-by-using-tensorflow\n",
    "# https://donaldpinckney.com/books/pytorch/book/ch2-linreg/2018-03-21-multi-variable.html\n",
    "# https://www.youtube.com/watch?v=Q4GNLhRtZNc\n",
    "# https://atmamani.github.io/projects/ml/coursera-gd-multivariate-linear-regression/\n",
    "# https://online.stat.psu.edu/stat462/sites/onlinecourses.science.psu.edu.stat462/files/05mlr/eq_matrix_notation/index.gif\n",
    "\n",
    "# Multivariable Logistic Regression for matricies.\n",
    "# target = flux1 + flux2 +... flux500 + b\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior() \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "00002-01b2c7d8-707d-4aa6-b424-ad8ecbbd1f58",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1634168366505,
    "source_hash": "93c1b31e",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#retrieve and format data - into labels from the dataset\n",
    "def labels(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    data_y = data['LABEL']\n",
    "    data_y-= 1\n",
    "    return data_y.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_id": "00007-f2dc2ae5-f310-4a14-8d71-88384e4f6257",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1634168452778,
    "source_hash": "27c812bc",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Logistic Layer using a sigmoid function\n",
    "def logistic_layer(y):\n",
    "    y = np.array(y)\n",
    "    y = 1 / (1 + exp(-y)) # sigmoid function\n",
    "    y = y.ravel()\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "00008-b837a0bd-a370-4dec-80f9-4f68a9cd9f78",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1,
    "execution_start": 1634168452789,
    "source_hash": "b7072dad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Calculate an accuracy metric\n",
    "def accuracy(predicted_y, true_y):\n",
    "    true_y = np.array(true_y).ravel()\n",
    "    counter = 0\n",
    "    for i in range(len(true_y)):\n",
    "        p_y = predicted_y[i]\n",
    "        t_y = true_y[i]\n",
    "        if (p_y>.5 and t_y == 1) or (p_y < .5 and t_y == 0):\n",
    "            counter+=1\n",
    "    counter = (counter/ len(true_y)) * 100\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "00003-24aa0dac-d955-4941-8ed2-9ad14c317e71",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5067,
    "execution_start": 1634168366515,
    "source_hash": "dbbaced2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"../archive/ProcessData.npy\", 'rb') as f:\n",
    "        training_data_x = np.load(f)\n",
    "        test_x = np.load(f)\n",
    "\n",
    "training_data_x = training_data_x.transpose()\n",
    "training_data_y = labels(\"../archive/exoTrain.csv\").transpose()\n",
    "training_data_y = training_data_y.to_numpy().reshape(1,training_data_x.shape[1])\n",
    "\n",
    "#set hyperparameters & variables\n",
    "learning_rate = 0.0003\n",
    "epochs = 300\n",
    "display_step = 5\n",
    "n_samples = training_data_x.shape[1]\n",
    "col_num = training_data_x.shape[0]\n",
    "\n",
    "X = tf.placeholder(tf.float32, [col_num, n_samples])\n",
    "Y = tf.placeholder(tf.float32, [1, n_samples]) #resulting dimenstion of W*X matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "00004-9f09321a-12c4-4c03-9d19-642a45a3f3b0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 19,
    "execution_start": 1634168371590,
    "source_hash": "54f103e4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We want the weight vector to correspond one to one with every column\n",
    "W = tf.Variable(tf.zeros([1,col_num], dtype=np.float32), name=\"weight\")\n",
    "b = tf.Variable(tf.zeros([1, ], dtype=np.float32), name=\"bias\")\n",
    "\n",
    "#matrix multiplication requires outer dimension of W to be equal to be equal to the inner dimension of X: \n",
    "# (1,col_num) & (col_num, num_samples) - this is why we transpose X\n",
    "pred = tf.matmul(W, X) + b # yâ€²(x,A,b)=Ax+b linear matrix equation\n",
    "\n",
    "error = tf.reduce_sum((pred-Y)**2) / (n_samples * 2) #MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "00005-5636fef9-095b-4767-984f-a967c95b5804",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 81157,
    "execution_start": 1634168371618,
    "source_hash": "e943c521",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-15 08:34:59.138692: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 08:34:59.146915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 08:34:59.147270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 08:34:59.148372: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-15 08:34:59.148722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 08:34:59.149226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 08:34:59.149723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 08:34:59.621697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 08:34:59.622292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 08:34:59.622771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-15 08:34:59.623244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 449 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 0, Loss = 0.00363672, Weights = [[0. 0. 0. ... 0. 0. 0.]], Bias = [0.]\n",
      "Epoch = 5, Loss = 0.00326905, Weights = [[-1.7637696e-05 -1.0637308e-05 -5.8852652e-06 ...  8.1179751e-06\n",
      "   4.3148022e-05  7.2313887e-06]], Bias = [5.021824e-06]\n",
      "Epoch = 10, Loss = 0.00309243, Weights = [[-3.3410441e-05 -2.1227672e-05 -1.2496499e-05 ...  9.3573517e-06\n",
      "   6.7577348e-05  8.1766075e-06]], Bias = [6.671241e-06]\n",
      "Epoch = 15, Loss = 0.002976, Weights = [[-4.5843608e-05 -2.9622408e-05 -1.6901142e-05 ...  8.8536217e-06\n",
      "   8.4857704e-05  6.8007580e-06]], Bias = [7.929255e-06]\n",
      "Epoch = 20, Loss = 0.0028899, Weights = [[-5.5964447e-05 -3.6387188e-05 -1.9594821e-05 ...  7.7834165e-06\n",
      "   9.8762044e-05  4.0063283e-06]], Bias = [9.014535e-06]\n",
      "Epoch = 25, Loss = 0.0028221, Weights = [[-6.4502950e-05 -4.1986044e-05 -2.1076377e-05 ...  6.6589737e-06\n",
      "   1.1090072e-04  2.9912158e-07]], Bias = [9.990931e-06]\n",
      "Epoch = 30, Loss = 0.00276649, Weights = [[-7.1939758e-05 -4.6735484e-05 -2.1694028e-05 ...  5.7127409e-06\n",
      "   1.2201469e-04 -4.0037194e-06]], Bias = [1.0891045e-05]\n",
      "Epoch = 35, Loss = 0.00271956, Weights = [[-7.8592195e-05 -5.0850558e-05 -2.1684455e-05 ...  5.0415106e-06\n",
      "   1.3246811e-04 -8.7021454e-06]], Bias = [1.1735075e-05]\n",
      "Epoch = 40, Loss = 0.00267908, Weights = [[-8.4671359e-05 -5.4480068e-05 -2.1209993e-05 ...  4.6738742e-06\n",
      "   1.4245162e-04 -1.3669883e-05]], Bias = [1.2536582e-05]\n",
      "Epoch = 45, Loss = 0.0026436, Weights = [[-9.0319016e-05 -5.7729485e-05 -2.0384003e-05 ...  4.6044011e-06\n",
      "   1.5207149e-04 -1.8826348e-05]], Bias = [1.3305099e-05]\n",
      "Epoch = 50, Loss = 0.00261207, Weights = [[-9.5631323e-05 -6.0675433e-05 -1.9287352e-05 ...  4.8116131e-06\n",
      "   1.6139064e-04 -2.4118795e-05]], Bias = [1.4047534e-05]\n",
      "Epoch = 55, Loss = 0.00258375, Weights = [[-1.0067436e-04 -6.3374930e-05 -1.7979077e-05 ...  5.2675250e-06\n",
      "   1.7044869e-04 -2.9511228e-05]], Bias = [1.4769026e-05]\n",
      "Epoch = 60, Loss = 0.0025581, Weights = [[-1.0549415e-04 -6.5871318e-05 -1.6503245e-05 ...  5.9426766e-06\n",
      "   1.7927231e-04 -3.4977682e-05]], Bias = [1.5473475e-05]\n",
      "Epoch = 65, Loss = 0.00253468, Weights = [[-1.1012324e-04 -6.8198126e-05 -1.4893458e-05 ...  6.8086765e-06\n",
      "   1.8788056e-04 -4.0498246e-05]], Bias = [1.6163904e-05]\n",
      "Epoch = 70, Loss = 0.00251316, Weights = [[-1.1458507e-04 -7.0381691e-05 -1.3175856e-05 ...  7.8393832e-06\n",
      "   1.9628805e-04 -4.6056717e-05]], Bias = [1.684269e-05]\n",
      "Epoch = 75, Loss = 0.00249328, Weights = [[-1.1889688e-04 -7.2442941e-05 -1.1371135e-05 ...  9.0113463e-06\n",
      "   2.0450648e-04 -5.1639287e-05]], Bias = [1.751174e-05]\n",
      "Epoch = 80, Loss = 0.00247483, Weights = [[-1.2307162e-04 -7.4398711e-05 -9.4959332e-06 ...  1.0303854e-05\n",
      "   2.1254567e-04 -5.7233785e-05]], Bias = [1.817261e-05]\n",
      "Epoch = 85, Loss = 0.00245763, Weights = [[-1.2711923e-04 -7.6262608e-05 -7.5638218e-06 ...  1.1698802e-05\n",
      "   2.2041425e-04 -6.2829276e-05]], Bias = [1.8826573e-05]\n",
      "Epoch = 90, Loss = 0.00244155, Weights = [[-1.31047636e-04 -7.80457995e-05 -5.58600868e-06 ...  1.31804445e-05\n",
      "   2.28119883e-04 -6.84158513e-05]], Bias = [1.9474697e-05]\n",
      "Epoch = 95, Loss = 0.00242645, Weights = [[-1.3486321e-04 -7.9757439e-05 -3.5718506e-06 ...  1.4735140e-05\n",
      "   2.3566950e-04 -7.3984469e-05]], Bias = [2.0117875e-05]\n",
      "Epoch = 100, Loss = 0.00241223, Weights = [[-1.3857134e-04 -8.1405131e-05 -1.5292256e-06 ...  1.6351105e-05\n",
      "   2.4306952e-04 -7.9526930e-05]], Bias = [2.0756872e-05]\n",
      "Epoch = 105, Loss = 0.00239881, Weights = [[-1.4217666e-04 -8.2995219e-05  5.3516283e-07 ...  1.8018154e-05\n",
      "   2.5032586e-04 -8.5035797e-05]], Bias = [2.139234e-05]\n",
      "Epoch = 110, Loss = 0.00238612, Weights = [[-1.4568321e-04 -8.4533065e-05  2.6155819e-06 ...  1.9727495e-05\n",
      "   2.5744396e-04 -9.0504363e-05]], Bias = [2.2024844e-05]\n",
      "Epoch = 115, Loss = 0.00237408, Weights = [[-1.4909466e-04 -8.6023218e-05  4.7070725e-06 ...  2.1471542e-05\n",
      "   2.6442902e-04 -9.5926640e-05]], Bias = [2.2654876e-05]\n",
      "Epoch = 120, Loss = 0.00236264, Weights = [[-1.5241437e-04 -8.7469576e-05  6.8053450e-06 ...  2.3243734e-05\n",
      "   2.7128583e-04 -1.0129729e-04]], Bias = [2.328286e-05]\n",
      "Epoch = 125, Loss = 0.00235175, Weights = [[-1.5564544e-04 -8.8875517e-05  8.9066580e-06 ...  2.5038407e-05\n",
      "   2.7801885e-04 -1.0661160e-04]], Bias = [2.3909171e-05]\n",
      "Epoch = 130, Loss = 0.00234137, Weights = [[-1.5879086e-04 -9.0243971e-05  1.1007746e-05 ...  2.6850663e-05\n",
      "   2.8463241e-04 -1.1186546e-04]], Bias = [2.4534133e-05]\n",
      "Epoch = 135, Loss = 0.00233146, Weights = [[-1.6185339e-04 -9.1577531e-05  1.3105726e-05 ...  2.8676266e-05\n",
      "   2.9113039e-04 -1.1705528e-04]], Bias = [2.5158033e-05]\n",
      "Epoch = 140, Loss = 0.00232198, Weights = [[-1.6483570e-04 -9.2878516e-05  1.5198068e-05 ...  3.0511543e-05\n",
      "   2.9751658e-04 -1.2217800e-04]], Bias = [2.5781132e-05]\n",
      "Epoch = 145, Loss = 0.0023129, Weights = [[-1.6774038e-04 -9.4148985e-05  1.7282537e-05 ...  3.2353324e-05\n",
      "   3.0379457e-04 -1.2723097e-04]], Bias = [2.6403648e-05]\n",
      "Epoch = 150, Loss = 0.00230419, Weights = [[-1.7056987e-04 -9.5390809e-05  1.9357163e-05 ...  3.4198845e-05\n",
      "   3.0996770e-04 -1.3221205e-04]], Bias = [2.7025786e-05]\n",
      "Epoch = 155, Loss = 0.00229583, Weights = [[-1.7332655e-04 -9.6605705e-05  2.1420197e-05 ...  3.6045731e-05\n",
      "   3.1603911e-04 -1.3711942e-04]], Bias = [2.7647719e-05]\n",
      "Epoch = 160, Loss = 0.0022878, Weights = [[-1.7601275e-04 -9.7795237e-05  2.3470095e-05 ...  3.7891910e-05\n",
      "   3.2201182e-04 -1.4195162e-04]], Bias = [2.8269604e-05]\n",
      "Epoch = 165, Loss = 0.00228007, Weights = [[-1.7863065e-04 -9.8960860e-05  2.5505491e-05 ...  3.9735591e-05\n",
      "   3.2788867e-04 -1.4670752e-04]], Bias = [2.8891585e-05]\n",
      "Epoch = 170, Loss = 0.00227262, Weights = [[-1.8118242e-04 -1.0010393e-04  2.7525177e-05 ...  4.1575207e-05\n",
      "   3.3367233e-04 -1.5138625e-04]], Bias = [2.9513782e-05]\n",
      "Epoch = 175, Loss = 0.00226545, Weights = [[-1.8367013e-04 -1.0122571e-04  2.9528093e-05 ...  4.3409422e-05\n",
      "   3.3936545e-04 -1.5598725e-04]], Bias = [3.0136302e-05]\n",
      "Epoch = 180, Loss = 0.00225853, Weights = [[-1.86095771e-04 -1.02327394e-04  3.15132966e-05 ...  4.52370514e-05\n",
      "   3.44970409e-04 -1.60510128e-04]], Bias = [3.0759245e-05]\n",
      "Epoch = 185, Loss = 0.00225185, Weights = [[-1.8846129e-04 -1.0341009e-04  3.3479981e-05 ...  4.7057103e-05\n",
      "   3.5048963e-04 -1.6495473e-04]], Bias = [3.1382693e-05]\n",
      "Epoch = 190, Loss = 0.00224539, Weights = [[-1.9076855e-04 -1.0447487e-04  3.5427416e-05 ...  4.8868678e-05\n",
      "   3.5592527e-04 -1.6932105e-04]], Bias = [3.2006723e-05]\n",
      "Epoch = 195, Loss = 0.00223915, Weights = [[-1.93019339e-04 -1.05522726e-04  3.73549919e-05 ...  5.06710421e-05\n",
      "   3.61279468e-04 -1.73609296e-04]], Bias = [3.2631408e-05]\n",
      "Epoch = 200, Loss = 0.0022331, Weights = [[-1.9521541e-04 -1.0655462e-04  3.9262162e-05 ...  5.2463529e-05\n",
      "   3.6655428e-04 -1.7781976e-04]], Bias = [3.3256798e-05]\n",
      "Epoch = 205, Loss = 0.00222725, Weights = [[-1.97358473e-04 -1.07571446e-04  4.11484834e-05 ...  5.42455782e-05\n",
      "   3.71751696e-04 -1.81952884e-04]], Bias = [3.3882956e-05]\n",
      "Epoch = 210, Loss = 0.00222158, Weights = [[-1.9945008e-04 -1.0857409e-04  4.3013559e-05 ...  5.6016699e-05\n",
      "   3.7687353e-04 -1.8600925e-04]], Bias = [3.450992e-05]\n",
      "Epoch = 215, Loss = 0.00221609, Weights = [[-2.0149180e-04 -1.0956335e-04  4.4857064e-05 ...  5.7776488e-05\n",
      "   3.8192162e-04 -1.8998947e-04]], Bias = [3.513773e-05]\n",
      "Epoch = 220, Loss = 0.00221075, Weights = [[-2.0348516e-04 -1.1054003e-04  4.6678731e-05 ...  5.9524580e-05\n",
      "   3.8689768e-04 -1.9389427e-04]], Bias = [3.5766425e-05]\n",
      "Epoch = 225, Loss = 0.00220558, Weights = [[-2.0543158e-04 -1.1150487e-04  4.8478349e-05 ...  6.1260675e-05\n",
      "   3.9180336e-04 -1.9772450e-04]], Bias = [3.6396028e-05]\n",
      "Epoch = 230, Loss = 0.00220055, Weights = [[-2.0733247e-04 -1.1245858e-04  5.0255752e-05 ...  6.2984524e-05\n",
      "   3.9664027e-04 -2.0148097e-04]], Bias = [3.702657e-05]\n",
      "Epoch = 235, Loss = 0.00219567, Weights = [[-2.0918918e-04 -1.1340186e-04  5.2010811e-05 ...  6.4695909e-05\n",
      "   4.0140995e-04 -2.0516463e-04]], Bias = [3.765807e-05]\n",
      "Epoch = 240, Loss = 0.00219092, Weights = [[-2.11002960e-04 -1.14335344e-04  5.37434680e-05 ...  6.63946412e-05\n",
      "   4.06113919e-04 -2.08776415e-04]], Bias = [3.829055e-05]\n",
      "Epoch = 245, Loss = 0.0021863, Weights = [[-2.12775049e-04 -1.15259674e-04  5.54536491e-05 ...  6.80805751e-05\n",
      "   4.10753535e-04 -2.12317318e-04]], Bias = [3.8924012e-05]\n",
      "Epoch = 250, Loss = 0.0021818, Weights = [[-2.14506683e-04 -1.16175426e-04  5.71413511e-05 ...  6.97535943e-05\n",
      "   4.15330200e-04 -2.15788386e-04]], Bias = [3.955849e-05]\n",
      "Epoch = 255, Loss = 0.00217743, Weights = [[-2.16198983e-04 -1.17083175e-04  5.88065886e-05 ...  7.14136040e-05\n",
      "   4.19845281e-04 -2.19190668e-04]], Bias = [4.019398e-05]\n",
      "Epoch = 260, Loss = 0.00217317, Weights = [[-2.17853056e-04 -1.17983465e-04  6.04493980e-05 ...  7.30605389e-05\n",
      "   4.24300088e-04 -2.22525225e-04]], Bias = [4.083049e-05]\n",
      "Epoch = 265, Loss = 0.00216902, Weights = [[-2.1946998e-04 -1.1887680e-04  6.2069848e-05 ...  7.4694333e-05\n",
      "   4.2869581e-04 -2.2579313e-04]], Bias = [4.1468033e-05]\n",
      "Epoch = 270, Loss = 0.00216497, Weights = [[-2.21050766e-04 -1.19763696e-04  6.36680343e-05 ...  7.63149510e-05\n",
      "   4.33033652e-04 -2.28995486e-04]], Bias = [4.2106607e-05]\n",
      "Epoch = 275, Loss = 0.00216103, Weights = [[-2.2259638e-04 -1.2064460e-04  6.5244058e-05 ...  7.7922370e-05\n",
      "   4.3731485e-04 -2.3213342e-04]], Bias = [4.2746215e-05]\n",
      "Epoch = 280, Loss = 0.00215718, Weights = [[-2.24107804e-04 -1.21519966e-04  6.67980421e-05 ...  7.95165834e-05\n",
      "   4.41540498e-04 -2.35208005e-04]], Bias = [4.3386855e-05]\n",
      "Epoch = 285, Loss = 0.00215342, Weights = [[-2.2558594e-04 -1.2239021e-04  6.8330104e-05 ...  8.1097591e-05\n",
      "   4.4571166e-04 -2.3822037e-04]], Bias = [4.402853e-05]\n",
      "Epoch = 290, Loss = 0.00214976, Weights = [[-2.2703168e-04 -1.2325573e-04  6.9840433e-05 ...  8.2665400e-05\n",
      "   4.4982941e-04 -2.4117161e-04]], Bias = [4.4671237e-05]\n",
      "Epoch = 295, Loss = 0.00214618, Weights = [[-2.2844588e-04 -1.2411692e-04  7.1329181e-05 ...  8.4220032e-05\n",
      "   4.5389481e-04 -2.4406283e-04]], Bias = [4.531497e-05]\n",
      "Epoch = 300, Loss = 0.00214268, Weights = [[-2.2982931e-04 -1.2497415e-04  7.2796509e-05 ...  8.5761530e-05\n",
      "   4.5790884e-04 -2.4689513e-04]], Bias = [4.595973e-05]\n",
      "Epoch = 305, Loss = 0.00213927, Weights = [[-2.3118281e-04 -1.2582773e-04  7.4242620e-05 ...  8.7289918e-05\n",
      "   4.6187246e-04 -2.4966963e-04]], Bias = [4.6605506e-05]\n",
      "Epoch = 310, Loss = 0.00213593, Weights = [[-2.3250713e-04 -1.2667803e-04  7.5667704e-05 ...  8.8805260e-05\n",
      "   4.6578661e-04 -2.5238737e-04]], Bias = [4.72523e-05]\n",
      "Epoch = 315, Loss = 0.00213267, Weights = [[-2.3380299e-04 -1.2752535e-04  7.7071963e-05 ...  9.0307592e-05\n",
      "   4.6965221e-04 -2.5504938e-04]], Bias = [4.7900096e-05]\n",
      "Epoch = 320, Loss = 0.00212948, Weights = [[-2.3507111e-04 -1.2836994e-04  7.8455589e-05 ...  9.1796959e-05\n",
      "   4.7347019e-04 -2.5765676e-04]], Bias = [4.8548893e-05]\n",
      "Epoch = 325, Loss = 0.00212636, Weights = [[-2.3631216e-04 -1.2921215e-04  7.9818827e-05 ...  9.3273433e-05\n",
      "   4.7724138e-04 -2.6021060e-04]], Bias = [4.919868e-05]\n",
      "Epoch = 330, Loss = 0.0021233, Weights = [[-2.3752681e-04 -1.3005218e-04  8.1161867e-05 ...  9.4737072e-05\n",
      "   4.8096664e-04 -2.6271187e-04]], Bias = [4.984945e-05]\n",
      "Epoch = 335, Loss = 0.00212031, Weights = [[-2.3871570e-04 -1.3089030e-04  8.2484949e-05 ...  9.6187956e-05\n",
      "   4.8464676e-04 -2.6516162e-04]], Bias = [5.050119e-05]\n",
      "Epoch = 340, Loss = 0.00211739, Weights = [[-2.3987945e-04 -1.3172676e-04  8.3788291e-05 ...  9.7626144e-05\n",
      "   4.8828253e-04 -2.6756083e-04]], Bias = [5.1153896e-05]\n",
      "Epoch = 345, Loss = 0.00211452, Weights = [[-2.4101864e-04 -1.3256176e-04  8.5072104e-05 ...  9.9051722e-05\n",
      "   4.9187482e-04 -2.6991050e-04]], Bias = [5.1807558e-05]\n",
      "Epoch = 350, Loss = 0.00211172, Weights = [[-2.4213384e-04 -1.3339552e-04  8.6336615e-05 ...  1.0046475e-04\n",
      "   4.9542432e-04 -2.7221162e-04]], Bias = [5.2462165e-05]\n",
      "Epoch = 355, Loss = 0.00210897, Weights = [[-2.4322562e-04 -1.3422820e-04  8.7582070e-05 ...  1.0186531e-04\n",
      "   4.9893174e-04 -2.7446516e-04]], Bias = [5.3117703e-05]\n",
      "Epoch = 360, Loss = 0.00210628, Weights = [[-2.4429450e-04 -1.3506002e-04  8.8808702e-05 ...  1.0325350e-04\n",
      "   5.0239777e-04 -2.7667204e-04]], Bias = [5.377417e-05]\n",
      "Epoch = 365, Loss = 0.00210364, Weights = [[-2.4534101e-04 -1.3589112e-04  9.0016743e-05 ...  1.0462939e-04\n",
      "   5.0582318e-04 -2.7883318e-04]], Bias = [5.443155e-05]\n",
      "Epoch = 370, Loss = 0.00210105, Weights = [[-2.4636567e-04 -1.3672169e-04  9.1206413e-05 ...  1.0599309e-04\n",
      "   5.0920859e-04 -2.8094952e-04]], Bias = [5.5089833e-05]\n",
      "Epoch = 375, Loss = 0.00209851, Weights = [[-2.4736891e-04 -1.3755188e-04  9.2377937e-05 ...  1.0734465e-04\n",
      "   5.1255478e-04 -2.8302192e-04]], Bias = [5.5749006e-05]\n",
      "Epoch = 380, Loss = 0.00209602, Weights = [[-2.4835128e-04 -1.3838180e-04  9.3531547e-05 ...  1.0868417e-04\n",
      "   5.1586225e-04 -2.8505130e-04]], Bias = [5.6409062e-05]\n",
      "Epoch = 385, Loss = 0.00209358, Weights = [[-2.4931319e-04 -1.3921161e-04  9.4667477e-05 ...  1.1001176e-04\n",
      "   5.1913178e-04 -2.8703854e-04]], Bias = [5.706999e-05]\n",
      "Epoch = 390, Loss = 0.00209119, Weights = [[-2.5025505e-04 -1.4004143e-04  9.5785959e-05 ...  1.1132749e-04\n",
      "   5.2236381e-04 -2.8898445e-04]], Bias = [5.7731773e-05]\n",
      "Epoch = 395, Loss = 0.00208884, Weights = [[-2.5117732e-04 -1.4087134e-04  9.6887205e-05 ...  1.1263146e-04\n",
      "   5.2555912e-04 -2.9088988e-04]], Bias = [5.8394406e-05]\n",
      "Epoch = 400, Loss = 0.00208653, Weights = [[-2.52080412e-04 -1.41701486e-04  9.79714387e-05 ...  1.13923765e-04\n",
      "   5.28718170e-04 -2.92755576e-04]], Bias = [5.9057875e-05]\n",
      "Epoch = 405, Loss = 0.00208427, Weights = [[-2.5296476e-04 -1.4253196e-04  9.9038887e-05 ...  1.1520450e-04\n",
      "   5.3184154e-04 -2.9458242e-04]], Bias = [5.972217e-05]\n",
      "Epoch = 410, Loss = 0.00208205, Weights = [[-0.00025383 -0.00014336  0.00010009 ...  0.00011647  0.00053493\n",
      "  -0.00029637]], Bias = [6.0387276e-05]\n",
      "Epoch = 415, Loss = 0.00207987, Weights = [[-0.00025468 -0.00014419  0.00010112 ...  0.00011773  0.00053798\n",
      "  -0.00029812]], Bias = [6.1053186e-05]\n",
      "Epoch = 420, Loss = 0.00207772, Weights = [[-0.00025551 -0.00014503  0.00010214 ...  0.00011898  0.000541\n",
      "  -0.00029984]], Bias = [6.171988e-05]\n",
      "Epoch = 425, Loss = 0.00207562, Weights = [[-0.00025632 -0.00014586  0.00010315 ...  0.00012021  0.00054399\n",
      "  -0.00030152]], Bias = [6.2387364e-05]\n",
      "Epoch = 430, Loss = 0.00207355, Weights = [[-0.00025712 -0.00014669  0.00010413 ...  0.00012144  0.00054694\n",
      "  -0.00030316]], Bias = [6.305562e-05]\n",
      "Epoch = 435, Loss = 0.00207152, Weights = [[-0.0002579  -0.00014753  0.0001051  ...  0.00012265  0.00054986\n",
      "  -0.00030477]], Bias = [6.372463e-05]\n",
      "Epoch = 440, Loss = 0.00206952, Weights = [[-0.00025866 -0.00014836  0.00010606 ...  0.00012385  0.00055275\n",
      "  -0.00030635]], Bias = [6.439438e-05]\n",
      "Epoch = 445, Loss = 0.00206756, Weights = [[-0.00025941 -0.0001492   0.000107   ...  0.00012505  0.00055561\n",
      "  -0.00030789]], Bias = [6.506486e-05]\n",
      "Epoch = 450, Loss = 0.00206563, Weights = [[-0.00026014 -0.00015003  0.00010793 ...  0.00012623  0.00055844\n",
      "  -0.0003094 ]], Bias = [6.5736065e-05]\n",
      "Epoch = 455, Loss = 0.00206373, Weights = [[-0.00026086 -0.00015087  0.00010884 ...  0.0001274   0.00056123\n",
      "  -0.00031088]], Bias = [6.6408e-05]\n",
      "Epoch = 460, Loss = 0.00206186, Weights = [[-0.00026156 -0.00015171  0.00010973 ...  0.00012856  0.000564\n",
      "  -0.00031232]], Bias = [6.708063e-05]\n",
      "Epoch = 465, Loss = 0.00206003, Weights = [[-0.00026224 -0.00015255  0.00011062 ...  0.00012971  0.00056673\n",
      "  -0.00031374]], Bias = [6.7753965e-05]\n",
      "Epoch = 470, Loss = 0.00205822, Weights = [[-0.00026292 -0.00015339  0.00011148 ...  0.00013084  0.00056944\n",
      "  -0.00031513]], Bias = [6.842798e-05]\n",
      "Epoch = 475, Loss = 0.00205644, Weights = [[-0.00026357 -0.00015423  0.00011234 ...  0.00013197  0.00057212\n",
      "  -0.00031649]], Bias = [6.9102665e-05]\n",
      "Epoch = 480, Loss = 0.0020547, Weights = [[-0.00026422 -0.00015507  0.00011318 ...  0.00013309  0.00057477\n",
      "  -0.00031782]], Bias = [6.9778005e-05]\n",
      "Epoch = 485, Loss = 0.00205298, Weights = [[-0.00026485 -0.00015592  0.00011401 ...  0.0001342   0.00057739\n",
      "  -0.00031912]], Bias = [7.045401e-05]\n",
      "Epoch = 490, Loss = 0.00205129, Weights = [[-0.00026546 -0.00015676  0.00011482 ...  0.0001353   0.00057998\n",
      "  -0.00032039]], Bias = [7.113064e-05]\n",
      "Epoch = 495, Loss = 0.00204962, Weights = [[-0.00026607 -0.00015761  0.00011562 ...  0.00013639  0.00058255\n",
      "  -0.00032164]], Bias = [7.180792e-05]\n",
      "Optimization Finished!\n",
      "Training error= 0.0020479795 Weights= [[-0.00026666 -0.00015845  0.00011641 ...  0.00013747  0.00058509\n",
      "  -0.00032286]] Bias= [7.248581e-05] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(error)\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "loss_arr = []\n",
    "acc_arr = []\n",
    "\n",
    "for t in range(epochs):\n",
    "    \n",
    "    _, current_loss, current_W, current_b = session.run([optimizer, error, W, b], feed_dict={\n",
    "        X: training_data_x,\n",
    "        Y: training_data_y\n",
    "    })\n",
    "\n",
    "    if t % display_step == 0:\n",
    "        print(\"Epoch = %g, Loss = %g, Weights = %s, Bias = %s\" % (t, current_loss, str(current_W), str(current_b)))\n",
    "    \n",
    "    loss_arr.append(current_loss)\n",
    "    #acc_arr.append(accuracy(logistic_layer(current_W * training_data_x + current_b), training_data_y))\n",
    "    acc_arr.append(accuracy(logistic_layer(np.dot(current_W, training_data_x) + current_b), training_data_y))\n",
    "    \n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "training_error = session.run(error, feed_dict={X: training_data_x, Y: training_data_y})\n",
    "print(\"Training error=\", training_error, \"Weights=\", session.run(W), \"Bias=\", session.run(b), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "00006-614e8ce1-d4bc-40d6-b8f7-3e04cbff6586",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1079,
    "execution_start": 1634168452795,
    "source_hash": "a84f9185",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy percentage:  48.59649122807018 %\n"
     ]
    }
   ],
   "source": [
    "test_x = test_x.transpose()\n",
    "test_y = labels(\"../archive/exoTest.csv\").transpose()\n",
    "test_y = test_y.to_numpy().reshape(1,test_x.shape[1])\n",
    "\n",
    "predicted_y = np.dot(current_W, test_x) + session.run(b)\n",
    "predicted_y = logistic_layer(predicted_y)\n",
    "\n",
    "print(\"Accuracy percentage: \", accuracy(predicted_y, test_y), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tf-models/multi-lr.npy', 'wb') as f:\n",
    "    np.save(f, session.run(W))\n",
    "    np.save(f, session.run(b))\n",
    "    np.save(f, loss_arr)\n",
    "    np.save(f, acc_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "9816afbc-27fe-4cd8-82a2-1b252605b243",
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
